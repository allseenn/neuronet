{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста.\n",
        "\n",
        "Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия.\n",
        "\n",
        "Можно использовать текст другого произведения"
      ],
      "metadata": {
        "id": "VqpC0flIybT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "2JGzQ_V5yVGd"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Вы – луч солнца, пронзающий хмурое небо понедельника. Ваша вера в себя – это сияющий маяк, освещающий путь к новым достижениям.\n",
        "Каждый день – это шанс стать супергероем своей жизни, и вы уже сделали первый шаг, одолев инерцию понедельника.\n",
        "Пусть ваши мысли парят, как орлы, а цели сияют, как звезды. Не бойтесь трудностей, ведь они – ступени к вершине успеха.\n",
        "Верьте в себя, действуйте смело, и тогда каждый день будет наполнен радостью побед и светом новых возможностей.\n",
        "\"\"\"\n",
        "text1 = text.replace('\\ufeff', '')\n",
        "text1 = re.sub(r'[^А-я ]', '', text)"
      ],
      "metadata": {
        "id": "PMpbGQoLyp2w"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34\n",
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)\n",
        "tokenizer.fit_on_texts(text1)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy14gG25ziSX",
        "outputId": "7a03deb3-cf7b-43b4-c2e9-03ff9c322628"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 1,\n",
              " 'е': 2,\n",
              " 'о': 3,\n",
              " 'н': 4,\n",
              " 'а': 5,\n",
              " 'с': 6,\n",
              " 'и': 7,\n",
              " 'т': 8,\n",
              " 'в': 9,\n",
              " 'д': 10,\n",
              " 'р': 11,\n",
              " 'л': 12,\n",
              " 'п': 13,\n",
              " 'й': 14,\n",
              " 'у': 15,\n",
              " 'ь': 16,\n",
              " 'к': 17,\n",
              " 'ы': 18,\n",
              " 'м': 19,\n",
              " 'я': 20,\n",
              " 'ю': 21,\n",
              " 'б': 22,\n",
              " 'ж': 23,\n",
              " 'з': 24,\n",
              " 'ш': 25,\n",
              " 'щ': 26,\n",
              " 'ц': 27,\n",
              " 'х': 28,\n",
              " 'г': 29,\n",
              " 'э': 30,\n",
              " 'ч': 31}"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_chars1 = 3\n",
        "data1 = tokenizer.texts_to_matrix(text1)\n",
        "n1 = data1.shape[0]-inp_chars1\n",
        "X1 = np.array([data1[i:i+inp_chars1, :] for i in range(n1)])\n",
        "Y1 = data1[inp_chars1:] #предсказание следующего символа"
      ],
      "metadata": {
        "id": "vvhVYCpWz7VN"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Input((inp_chars1, num_characters)))\n",
        "model1.add(SimpleRNN(500, activation='tanh'))\n",
        "model1.add(Dense(num_characters, activation='softmax'))\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9srvFkxR0MrA",
        "outputId": "fd2a2924-e96f-4ccf-fff0-aa6b57c9169f"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_19 (SimpleRNN)   (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model1.fit(X1, Y1, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMjUGXw00UBg",
        "outputId": "7ece5c30-b4f1-4b93-ee24-c225828338e1"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 19ms/step - loss: 3.3455 - accuracy: 0.1213\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.7203 - accuracy: 0.2449\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 2.4147 - accuracy: 0.2899\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 2.2127 - accuracy: 0.3371\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 2.0475 - accuracy: 0.3820\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 1.9267 - accuracy: 0.3820\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 1.8326 - accuracy: 0.4337\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 1.7491 - accuracy: 0.4270\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 1.6669 - accuracy: 0.4876\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.6218 - accuracy: 0.4629\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.5829 - accuracy: 0.4764\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.5314 - accuracy: 0.4787\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.5226 - accuracy: 0.5124\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.4872 - accuracy: 0.5146\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.4577 - accuracy: 0.5258\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.4160 - accuracy: 0.5303\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.3458 - accuracy: 0.5708\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.3616 - accuracy: 0.5416\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.3394 - accuracy: 0.5618\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.3070 - accuracy: 0.5506\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.2676 - accuracy: 0.5798\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.2598 - accuracy: 0.6202\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.2353 - accuracy: 0.5730\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.2097 - accuracy: 0.5978\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.2248 - accuracy: 0.5910\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.2012 - accuracy: 0.6090\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.1503 - accuracy: 0.6337\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.1799 - accuracy: 0.5978\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.1349 - accuracy: 0.6315\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.1335 - accuracy: 0.6000\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0984 - accuracy: 0.6292\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0773 - accuracy: 0.6337\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0864 - accuracy: 0.6337\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0621 - accuracy: 0.6180\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0367 - accuracy: 0.6427\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0394 - accuracy: 0.6449\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0356 - accuracy: 0.6404\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.0209 - accuracy: 0.6629\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.9973 - accuracy: 0.6697\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0023 - accuracy: 0.6404\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.9859 - accuracy: 0.6494\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.9517 - accuracy: 0.6854\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.9607 - accuracy: 0.6764\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.9220 - accuracy: 0.6989\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8878 - accuracy: 0.7101\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8912 - accuracy: 0.7056\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8958 - accuracy: 0.6764\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8638 - accuracy: 0.7034\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.8334 - accuracy: 0.7056\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.8690 - accuracy: 0.7191\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8390 - accuracy: 0.7258\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8578 - accuracy: 0.7191\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7814 - accuracy: 0.7438\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7765 - accuracy: 0.7461\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7851 - accuracy: 0.7393\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7760 - accuracy: 0.7528\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.7906 - accuracy: 0.7213\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7750 - accuracy: 0.7416\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7491 - accuracy: 0.7461\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7538 - accuracy: 0.7461\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7589 - accuracy: 0.7393\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7227 - accuracy: 0.7573\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.7267 - accuracy: 0.7416\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.6876 - accuracy: 0.7663\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.6863 - accuracy: 0.7910\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.6657 - accuracy: 0.7888\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7064 - accuracy: 0.7618\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.7596\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.6686 - accuracy: 0.7685\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.6372 - accuracy: 0.7820\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 15ms/step - loss: 0.6581 - accuracy: 0.7596\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.6362 - accuracy: 0.7888\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 16ms/step - loss: 0.5834 - accuracy: 0.8000\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.6227 - accuracy: 0.7910\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.6109 - accuracy: 0.7955\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.6038 - accuracy: 0.7978\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.6112 - accuracy: 0.8067\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.6125 - accuracy: 0.8067\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.6032 - accuracy: 0.7775\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.5921 - accuracy: 0.7955\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.6002 - accuracy: 0.7843\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.6163 - accuracy: 0.8045\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5744 - accuracy: 0.7798\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5783 - accuracy: 0.7955\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5453 - accuracy: 0.8135\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5581 - accuracy: 0.8022\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5295 - accuracy: 0.8247\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.5505 - accuracy: 0.8022\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5724 - accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5595 - accuracy: 0.8135\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5559 - accuracy: 0.8000\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5645 - accuracy: 0.8000\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5753 - accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.5253 - accuracy: 0.8202\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5332 - accuracy: 0.7933\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5352 - accuracy: 0.8180\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5004 - accuracy: 0.8247\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5082 - accuracy: 0.8202\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.5306 - accuracy: 0.8225\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.4712 - accuracy: 0.8090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars1):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars1, num_characters)\n",
        "\n",
        "    pred = model1.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "7O8vMNRd0aRS"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"себ\", 1)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km4mwp1G0nIM",
        "outputId": "34e7edb1-6c04-4557-b5d9-2c8cea64661c"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 141ms/step\n",
            "себя\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = text.replace('\\ufeff', '')"
      ],
      "metadata": {
        "id": "uyMnifnTTtMS"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount2 = 100\n",
        "tokenizer2 = Tokenizer(num_words=maxWordsCount2, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)\n",
        "tokenizer2.fit_on_texts([text2])"
      ],
      "metadata": {
        "id": "_IvgKuuGXf-W"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0g7Yq33nVz-",
        "outputId": "0779e89e-5226-459d-c7cc-d7c0eb83ccc9"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'и': 1,\n",
              " 'вы': 2,\n",
              " 'понедельника': 3,\n",
              " 'в': 4,\n",
              " 'себя': 5,\n",
              " 'это': 6,\n",
              " 'к': 7,\n",
              " 'каждый': 8,\n",
              " 'день': 9,\n",
              " 'как': 10,\n",
              " 'луч': 11,\n",
              " 'солнца': 12,\n",
              " 'пронзающий': 13,\n",
              " 'хмурое': 14,\n",
              " 'небо': 15,\n",
              " 'ваша': 16,\n",
              " 'вера': 17,\n",
              " 'сияющий': 18,\n",
              " 'маяк': 19,\n",
              " 'освещающий': 20,\n",
              " 'путь': 21,\n",
              " 'новым': 22,\n",
              " 'достижениям': 23,\n",
              " 'шанс': 24,\n",
              " 'стать': 25,\n",
              " 'супергероем': 26,\n",
              " 'своей': 27,\n",
              " 'жизни': 28,\n",
              " 'уже': 29,\n",
              " 'сделали': 30,\n",
              " 'первый': 31,\n",
              " 'шаг': 32,\n",
              " 'одолев': 33,\n",
              " 'инерцию': 34,\n",
              " 'пусть': 35,\n",
              " 'ваши': 36,\n",
              " 'мысли': 37,\n",
              " 'парят': 38,\n",
              " 'орлы': 39,\n",
              " 'а': 40,\n",
              " 'цели': 41,\n",
              " 'сияют': 42,\n",
              " 'звезды': 43,\n",
              " 'не': 44,\n",
              " 'бойтесь': 45,\n",
              " 'трудностей': 46,\n",
              " 'ведь': 47,\n",
              " 'они': 48,\n",
              " 'ступени': 49,\n",
              " 'вершине': 50,\n",
              " 'успеха': 51,\n",
              " 'верьте': 52,\n",
              " 'действуйте': 53,\n",
              " 'смело': 54,\n",
              " 'тогда': 55,\n",
              " 'будет': 56,\n",
              " 'наполнен': 57,\n",
              " 'радостью': 58,\n",
              " 'побед': 59,\n",
              " 'светом': 60,\n",
              " 'новых': 61,\n",
              " 'возможностей': 62}"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = tokenizer2.texts_to_sequences([text2])"
      ],
      "metadata": {
        "id": "CCEMKnbZXsRM"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res2 = keras.utils.to_categorical(data2[0], num_classes=maxWordsCount2)\n",
        "res2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZuNjy2AX0Y_",
        "outputId": "1a5f93b2-7aae-4b85-d441-10c84c722d42"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words2 = 3\n",
        "n2 = res2.shape[0]-inp_words2"
      ],
      "metadata": {
        "id": "6ja8o-0WX5FO"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = np.array([res2[i:i+inp_words2, :] for i in range(n2)])\n",
        "Y2 = res2[inp_words2:]"
      ],
      "metadata": {
        "id": "1Gi4GhoHX-Og"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Input((inp_words2, maxWordsCount2)))\n",
        "model2.add(SimpleRNN(256, activation='tanh', return_sequences=True))\n",
        "model2.add(Dropout(0.2))  # Добавляем dropout для уменьшения переобучения\n",
        "model2.add(SimpleRNN(256, activation='tanh'))\n",
        "model2.add(Dropout(0.2))  # Добавляем dropout для уменьшения переобучения\n",
        "model2.add(Dense(maxWordsCount2, activation='softmax'))\n",
        "model2.summary()\n",
        "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dASbI4E9YlMe",
        "outputId": "61536a87-bb9c-42b5-bd15-6cc740ab808d"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_26 (SimpleRNN)   (None, 3, 256)            91392     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 3, 256)            0         \n",
            "                                                                 \n",
            " simple_rnn_27 (SimpleRNN)   (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 100)               25700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 248420 (970.39 KB)\n",
            "Trainable params: 248420 (970.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X2, Y2, batch_size=32, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nKGiZXsY1Rs",
        "outputId": "64c520e7-adaf-48cb-cac7-fce3fe85a769"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "3/3 [==============================] - 2s 12ms/step - loss: 4.6824 - accuracy: 0.0000e+00\n",
            "Epoch 2/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.1923 - accuracy: 0.2857\n",
            "Epoch 3/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.8187 - accuracy: 0.6429\n",
            "Epoch 4/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.4330 - accuracy: 0.8429\n",
            "Epoch 5/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 3.0500 - accuracy: 0.9429\n",
            "Epoch 6/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 2.7133 - accuracy: 0.9429\n",
            "Epoch 7/25\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.3443 - accuracy: 0.9714\n",
            "Epoch 8/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.9760 - accuracy: 0.9571\n",
            "Epoch 9/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.5598 - accuracy: 0.9714\n",
            "Epoch 10/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.2748 - accuracy: 0.9714\n",
            "Epoch 11/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9932 - accuracy: 0.9714\n",
            "Epoch 12/25\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.7560 - accuracy: 0.9714\n",
            "Epoch 13/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.5551 - accuracy: 0.9857\n",
            "Epoch 14/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.4376 - accuracy: 0.9571\n",
            "Epoch 15/25\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.3371 - accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.2670 - accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.2310 - accuracy: 0.9857\n",
            "Epoch 18/25\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1620 - accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1570 - accuracy: 0.9857\n",
            "Epoch 20/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1315 - accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1189 - accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1020 - accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0894 - accuracy: 0.9857\n",
            "Epoch 24/25\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0948 - accuracy: 0.9857\n",
            "Epoch 25/25\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0870 - accuracy: 0.9857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78afe846e560>"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def buildPhrase2(phrase, str_len=10):\n",
        "    res = phrase\n",
        "    data = tokenizer2.texts_to_sequences([phrase])[0]\n",
        "    used_words = set(data)  # Множество уже использованных слов\n",
        "    prev_word = data[-1]  # Предыдущее слово\n",
        "    for i in range(str_len):\n",
        "        # Получаем вероятности для предсказания следующего слова\n",
        "        x = to_categorical(data[i: i + inp_words2], num_classes=maxWordsCount2)\n",
        "        inp = x.reshape(1, inp_words2, maxWordsCount2)\n",
        "        pred = model2.predict(inp)[0]\n",
        "\n",
        "        # Убираем вероятности для уже использованных слов\n",
        "        pred_filtered = [p if idx not in used_words else 0 for idx, p in enumerate(pred)]\n",
        "        # Убираем вероятности для предыдущего слова\n",
        "        pred_filtered[prev_word] = 0\n",
        "\n",
        "        # Выбираем индекс следующего слова с учетом фильтрации\n",
        "        indx = np.argmax(pred_filtered)\n",
        "        data.append(indx)\n",
        "\n",
        "        res += \" \" + tokenizer2.index_word[indx]\n",
        "        used_words.add(indx)  # Добавляем новое слово в множество использованных слов\n",
        "        prev_word = indx  # Обновляем предыдущее слово\n",
        "\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "NEEEUF7HZOgG"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resEnd = buildPhrase2(\"верьте в себя\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvu0OL-6ZTAP",
        "outputId": "80f7906f-6314-4e1d-81f0-e55a41aca2a9"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resEnd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OeohU_8ygqw6",
        "outputId": "ec2a369d-c710-47df-d038-a9b39e12ade6"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'верьте в себя действуйте смело и тогда каждый день будет наполнен радостью побед'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Расширил немного первоначальный текст, чтобы обогатить лексику.\n",
        "2. Текст поместил в переменную, а не в файл, для удобства редактирования\n",
        "3. Разделил переменные для первой и второй моделей, для устранения коллизий.\n",
        "4. Расширил model2, добавив несколько дополнительных слоев. Увеличил количество нейронов в рекуррентных слоях на 100%.\n",
        "5. Изменил функцию генерации фраз, добавив алгоритм проверки повторяющихся слов, чтобы исключить тавтологии.\n",
        "6. Уменьшил максимальное количество слов (maxWordsCount2) до 100, так как в моем массиве 62 уникальных слова.\n",
        "7. Во втором блокноте потренировался с готовыми языковыми моделями.\n"
      ],
      "metadata": {
        "id": "h1DlVi5q8sgy"
      }
    }
  ]
}